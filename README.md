# T4U Backend - Test Automation for You

> **AI-Powered Autonomous Test Automation**  
> Create and execute web tests using natural language. AI agents understand your testing goals and generate stable, reliable test automation using Playwright locators.

[![Python 3.13+](https://img.shields.io/badge/python-3.13+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![Playwright](https://img.shields.io/badge/Playwright-Latest-red.svg)](https://playwright.dev/)

**[Quick Start](QUICK_START.md)** â€¢ **[Deployment Guide](DEPLOYMENT.md)** â€¢ **[E2B Template Setup](E2B_TEMPLATE_SETUP.md)** â€¢ **[Contributing](CONTRIBUTING.md)**

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Quick Links](#quick-links)
- [Key Features](#key-features)
- [Architecture](#architecture)
- [Quick Start](#quick-start)
- [Technology Stack](#technology-stack)
- [Core Concepts](#core-concepts)
- [API Reference](#api-reference)
- [Development](#development)
- [Documentation](#documentation)
- [Contributing](#contributing)

---

## ğŸ”— Quick Links

- **[5-Minute Quick Start](QUICK_START.md)** - Get running immediately
- **[Deployment Guide](DEPLOYMENT.md)** - Deploy to Cloud Run, Docker, or VPS
- **[E2B Template Setup](E2B_TEMPLATE_SETUP.md)** - 6x faster sandbox startup
- **[Environment Variables](ENVIRONMENT.md)** - All configuration options
- **[Contributing Guidelines](CONTRIBUTING.md)** - How to contribute
- **[Open Source Checklist](OPEN_SOURCE_CHECKLIST.md)** - Pre-commit verification

---

## ğŸ¯ Overview

**T4U (Test for You)** is an AI-powered test automation platform that uses autonomous agents to create and execute web tests. Simply describe what you want to test in natural language, and T4U's AI agents will:

1. **Understand** your testing goal using Claude 3.5 Sonnet
2. **Execute** tests in isolated E2B sandboxes with Playwright
3. **Generate** stable test scripts using semantic locators
4. **Replay** tests deterministically for regression testing

**No more brittle selectors. No more manual test maintenance.**

### Key Features

#### ğŸ¯ Stable Test Automation
- **Semantic Locators** - Uses `by_role='button'`, `by_placeholder='Email'` instead of brittle element indices
- **Smart Exact Matching** - Intelligently disambiguates when multiple elements match
- **Works Across Updates** - Tests survive page structure changes

#### ğŸ¤– AI-Powered Intelligence
- **Natural Language** - Write tests in plain English: "Login and validate dashboard"
- **Autonomous Agents** - Claude 3.5 Sonnet understands complex testing tasks
- **Self-Validating** - AI includes assertions automatically

#### âš¡ Performance & Scalability
- **6x Faster Startup** - Custom E2B templates with pre-installed Playwright (10s vs 60s)
- **Parallel Execution** - Run multiple test cases simultaneously
- **Async Operations** - 3x faster overall execution

#### ğŸ¥ Real-Time Visibility
- **Live VNC Streaming** - Watch tests execute in real-time browser
- **Step-by-Step Updates** - Firestore real-time sync to frontend
- **Debug Logging** - Detailed execution traces

#### ğŸ”„ Deterministic Replay
- **Proven Steps** - Record once, replay infinitely
- **No AI Costs** - Replay without LLM inference
- **Built-in Validations** - Assert element visibility, URL changes, counts

#### ğŸ—ï¸ Developer Friendly
- **REST API + SSE** - Easy integration with any frontend
- **Comprehensive Docs** - Architecture, API reference, deployment guides
- **Open Source** - MIT License, contributions welcome

---

## ğŸ—ï¸ Architecture

### High-Level Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Frontend (React)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Test Cases â”‚  â”‚ Test Runs  â”‚  â”‚ Live VNC Viewer     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ REST API / SSE
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FastAPI Server (api_server.py)                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ /agent/    â”‚  â”‚ /api/runs/ â”‚  â”‚ Session Management  â”‚  â”‚
â”‚  â”‚  start     â”‚  â”‚  execute   â”‚  â”‚ (pause/resume/stop) â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Agent Layer                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚         E2BTestOpsAI (Main Agent)                  â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚    â”‚
â”‚  â”‚  â”‚ToolCallAgent â”‚  â”‚  BaseAgent   â”‚              â”‚    â”‚
â”‚  â”‚  â”‚  (ReAct)     â”‚  â”‚  (State Mgr) â”‚              â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                        â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              Tool Collection                       â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  â”‚ Planning â”‚ â”‚ Browser  â”‚ â”‚ Sub-Agent        â”‚  â”‚    â”‚
â”‚  â”‚  â”‚ Tool     â”‚ â”‚ Tool     â”‚ â”‚ Tool             â”‚  â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  â”‚ Vision   â”‚ â”‚ AI Steps â”‚ â”‚ Terminate        â”‚  â”‚    â”‚
â”‚  â”‚  â”‚ Tool     â”‚ â”‚ Tool     â”‚ â”‚ Tool             â”‚  â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Sandbox & LLM Layer                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  E2B Sandbox       â”‚         â”‚   LLM Provider       â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚ Playwright   â”‚  â”‚         â”‚  â”‚ Claude 3.5     â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ Browser      â”‚  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚ Sonnet         â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚ Desktop (VNC)â”‚  â”‚         â”‚  â”‚ Google Gemini  â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚         â”‚  â”‚ (Optional)     â”‚  â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚  â”‚ Screenshots  â”‚  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Data Storage Layer                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Firebase Firestore â”‚         â”‚ Firebase Storage     â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚ Sessions     â”‚  â”‚         â”‚  â”‚ Screenshots    â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ Test Cases   â”‚  â”‚         â”‚  â”‚ Artifacts      â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ Steps        â”‚  â”‚         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚  â”‚ Runs         â”‚  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Architecture Principles

1. **Agent-Based**: Autonomous agents make decisions using LLM reasoning
2. **Tool-Based Abstraction**: Actions abstracted into reusable tools
3. **Sandbox Isolation**: Each session runs in isolated E2B sandbox
4. **ReAct Pattern**: Think â†’ Act cycle for decision making
5. **Hierarchical Delegation**: Main agent delegates to sub-agents
6. **Real-time Sync**: Firestore provides live updates to frontend

---

## ğŸ“¦ Core Entities

### 1. **Agent Session**
A single execution of the AI agent from start to completion.

**Key Attributes:**
- `session_id`: Unique identifier
- `user_id`: User who initiated the session
- `tenant_id`: Organization/tenant ID
- `test_case_id`: Associated test case (optional)
- `sandbox_id`: E2B sandbox identifier
- `vnc_url`: WebSocket URL for live browser viewing
- `status`: Session state (`initializing`, `running`, `paused`, `completed`, `failed`)
- `artifacts`: Files created during session
- `proven_steps`: Successful actions for replay
- `total_tokens`, `total_cost`: LLM usage tracking

**Firestore Collection:** `agent_sessions`

---

### 2. **Agent Step**
A single action taken by the agent (think + act cycle).

**Key Attributes:**
- `step_number`: Sequential step counter
- `timestamp`: When step occurred
- `thinking`: LLM's reasoning about what to do
- `tool_calls`: List of tools executed
- `tool_results`: Results from tool execution
- `status`: Step status (`thinking`, `executing`, `success`, `error`)
- `screenshot_urls`: Screenshots taken during step

**Firestore Collection:** `agent_steps`

---

### 3. **Test Case**
A validated sequence of actions that can be replayed.

**Key Attributes:**
- `test_case_id`: Unique identifier
- `session_id`: Original session that created this test case
- `proven_steps`: Validated action sequence
- `execution_history_raw`: Full execution log for AI analysis
- `summary`: Human-readable description
- `status`: Test case status

**Firestore Collection:** `test_cases`

**Proven Step Structure:**
```python
{
  "step_number": 1,
  "action": {
    "tool_name": "e2b_browser",
    "arguments": {
      "action": "navigate_to",
      "url": "https://example.com"
    }
  },
  "validation": {
    "type": "assert_element_visible",
    "description": "Login button is visible",
    "search_text": "Sign In"
  }
}
```

---

### 4. **Test Run**
Execution of multiple test cases (regression suite).

**Key Attributes:**
- `run_id`: Unique identifier
- `tenant_id`: Organization ID
- `project_id`: Project this run belongs to
- `test_case_ids`: List of test cases to execute
- `status`: Run status (`pending`, `running`, `completed`, `failed`)
- `results`: Per-test-case results
- `started_at`, `completed_at`: Timing information
- `current_test_case_index`: Progress tracking

**Firestore Collection:** `runs`

**Result Structure:**
```python
results: {
  "test_case_1": {
    "status": "passed",
    "vnc_url": "wss://...",
    "current_step": 8,
    "total_steps": 8,
    "passed_steps": 8,
    "failed_steps": 0,
    "started_at": "2025-10-27T...",
    "completed_at": "2025-10-27T..."
  }
}
```

---

### 5. **E2B Sandbox**
Isolated cloud environment for test execution.

**Key Features:**
- Ubuntu-based container (4 vCPUs, 4GB RAM)
- Playwright + Chromium pre-installed
- Desktop environment (Xvfb + Fluxbox + VNC)
- Full internet access
- File system isolation
- Auto-cleanup after session

**Access:**
- VNC WebSocket: `wss://<host>:6080/websockify`
- HTTP Endpoint: `https://<sandbox-id>.e2b.dev`

---

### 6. **Plan**
High-level task breakdown created by the planning tool.

**Structure:**
```python
{
  "plan_id": "task_login_001",
  "title": "Login and validate dashboard",
  "steps": [
    "Navigate to login page",
    "Complete login process",  # Delegated to sub-agent
    "Validate dashboard elements"
  ],
  "step_statuses": ["completed", "in_progress", "not_started"]
}
```

**States:** `not_started`, `in_progress`, `completed`, `blocked`

---

## ğŸ”„ Main Logic Flow

### 1. **Agent Execution Flow** (`/agent/start`)

```
User Request
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Create Agent Session         â”‚
â”‚    - Generate session_id        â”‚
â”‚    - Save to Firestore          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Initialize E2B Sandbox       â”‚
â”‚    - Create sandbox (~30s)      â”‚
â”‚    - Start Playwright browser   â”‚
â”‚    - Start VNC desktop          â”‚
â”‚    - Get VNC WebSocket URL      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Initialize Agent Tools       â”‚
â”‚    - Planning Tool              â”‚
â”‚    - Browser Tool (Playwright)  â”‚
â”‚    - Vision Tool (screenshots)  â”‚
â”‚    - Sub-Agent Tool             â”‚
â”‚    - AI Proven Steps Tool       â”‚
â”‚    - Terminate Tool             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. ReAct Loop (max_steps: 20)  â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚    â”‚ Think Phase            â”‚   â”‚
â”‚    â”‚  - Send messages to LLMâ”‚   â”‚
â”‚    â”‚  - LLM returns thinkingâ”‚   â”‚
â”‚    â”‚    + tool calls        â”‚   â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚            â”‚                     â”‚
â”‚            â–¼                     â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚    â”‚ Act Phase              â”‚   â”‚
â”‚    â”‚  - Execute tools       â”‚   â”‚
â”‚    â”‚  - Save results        â”‚   â”‚
â”‚    â”‚  - Update Firestore    â”‚   â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚            â”‚                     â”‚
â”‚            â”‚ Next Step           â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                  â”‚
â”‚    Exit Conditions:              â”‚
â”‚     - terminate() called         â”‚
â”‚     - max_steps reached          â”‚
â”‚     - error state                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Session Completion           â”‚
â”‚    - Mark incomplete steps      â”‚
â”‚    - Save proven steps          â”‚
â”‚    - Update session status      â”‚
â”‚    - Cleanup sandbox            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
         Complete
```

---

### 2. **Think-Act (ReAct) Pattern**

Each step follows the ReAct pattern:

```python
async def step() -> str:
    """Execute single step"""
    should_act = await self.think()  # Decide what to do
    if not should_act:
        return "Thinking complete"
    return await self.act()  # Execute decision
```

**Think Phase:**
1. Build message history (system prompt + conversation)
2. Send to LLM with available tools
3. LLM returns:
   - `content`: Reasoning about next action
   - `tool_calls`: List of tools to execute
4. Store thinking and tool calls in memory

**Act Phase:**
1. Execute each tool call sequentially
2. Capture tool results
3. Add tool results to message history
4. Save step to Firestore
5. Update session metadata

---

### 3. **Sub-Agent Delegation Flow**

Main agent delegates complex tasks to sub-agents:

```
Main Agent (Step 5)
    â”‚
    â”‚ "Login to the application"
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ e2b_sub_agent(                  â”‚
â”‚   task="Login with credentials",â”‚
â”‚   context="On login page",      â”‚
â”‚   max_attempts=20               â”‚
â”‚ )                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Sub-Agent Execution             â”‚
â”‚  - Creates isolated agent       â”‚
â”‚  - Shares sandbox & tools       â”‚
â”‚  - Independent LLM context      â”‚
â”‚  - Tries multiple approaches    â”‚
â”‚  - Returns only summary         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”‚ Summary Result
             â–¼
Main Agent (Step 5 complete)
"âœ… Login successful, now on dashboard"
```

**Benefits:**
- Main agent context stays clean (1 step vs 10+ steps)
- Sub-agent can retry without bloating main conversation
- Failures isolated to sub-agent
- Main agent only sees success/failure summary

---

### 4. **Test Run Execution Flow** (`/api/runs/execute`)

```
POST /api/runs/execute
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Validate Run                 â”‚
â”‚    - Check run exists           â”‚
â”‚    - Get test_case_ids          â”‚
â”‚    - Reset results              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Start Background Execution   â”‚
â”‚    - Return immediately         â”‚
â”‚    - Execute async              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                 â”‚
    â”‚ Sequential      â”‚  Parallel
    â”‚ Execution       â”‚  Execution
    â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ For each TC: â”‚  â”‚ All TCs at   â”‚
â”‚              â”‚  â”‚ once with    â”‚
â”‚ 1. Create    â”‚  â”‚ asyncio      â”‚
â”‚    sandbox   â”‚  â”‚ .gather()    â”‚
â”‚ 2. Execute   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚    steps     â”‚
â”‚ 3. Update    â”‚
â”‚    Firestore â”‚
â”‚ 4. Cleanup   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Per Test Case Execution      â”‚
â”‚    For each proven_step:        â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚    â”‚ - Get tool + arguments â”‚   â”‚
â”‚    â”‚ - Execute tool.execute â”‚   â”‚
â”‚    â”‚ - Check success        â”‚   â”‚
â”‚    â”‚ - Run validation       â”‚   â”‚
â”‚    â”‚ - Update Firestore     â”‚   â”‚
â”‚    â”‚ - Handle errors        â”‚   â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Aggregate Results            â”‚
â”‚    - Count passed/failed        â”‚
â”‚    - Update run status          â”‚
â”‚    - Set completed_at           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
         Complete
```

**Firestore Updates (Real-time):**
- `results.{test_case_id}.status`: `pending` â†’ `running` â†’ `passed`/`failed`
- `results.{test_case_id}.current_step`: Progress counter
- `results.{test_case_id}.vnc_url`: Live browser URL
- `current_test_case_index`: Which test is running

Frontend listens to these updates for live progress display.

---

## ğŸ› ï¸ Technology Stack

### Backend
- **Python 3.13**
- **FastAPI** - REST API + Server-Sent Events (SSE)
- **Pydantic** - Data validation and schemas
- **asyncio** - Asynchronous execution

### AI & LLM
- **Claude 3.5 Sonnet (Anthropic)** - Primary LLM
- **Google Gemini** - Alternative LLM (optional)
- **OpenAI SDK** - LLM client interface

### Browser Automation
- **Playwright** - Browser control
- **Chromium** - Headless browser
- **E2B SDK** - Sandbox management

### Data Storage
- **Firebase Firestore** - Real-time database
- **Firebase Storage** - Screenshot & artifact storage
- **Firebase Admin SDK** - Server-side Firebase access

### Infrastructure
- **E2B (v2.2.0)** - Serverless sandbox environments
- **Docker** - E2B sandbox base image
- **VNC + noVNC** - Remote desktop viewing

### Development
- **pytest** - Testing framework
- **uvicorn** - ASGI server
- **loguru** - Structured logging

---

## ğŸš€ Quick Start

**Get running in 5 minutes!** See **[QUICK_START.md](QUICK_START.md)** for detailed instructions.

### TL;DR

```bash
# 1. Clone & Install
git clone https://github.com/t4u-automation/t4u-backend.git
cd t4u-backend
python3.13 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 2. Configure (copy example and add your API keys)
cp config/config.example-model-anthropic.toml config/config.toml
nano config/config.toml  # Add: Anthropic key, E2B key, Firebase bucket

# 3. Add Firebase credentials
# Download from Firebase Console and save as:
# config/firebase-service-account.json

# 4. Run
python api_server.py
# Server: http://localhost:8000
# Docs: http://localhost:8000/docs
```

For detailed setup, production deployment, and E2B template configuration, see:
- **[QUICK_START.md](QUICK_START.md)** - Step-by-step setup guide
- **[DEPLOYMENT.md](DEPLOYMENT.md)** - Cloud Run, Docker, VPS deployment  
- **[E2B_TEMPLATE_SETUP.md](E2B_TEMPLATE_SETUP.md)** - Custom template for 6x faster startup
- **[ENVIRONMENT.md](ENVIRONMENT.md)** - All configuration options

---

## ğŸ“¡ API Reference

### Agent Endpoints

#### `POST /agent/start`
Start a new agent session with SSE streaming.

**Request:**
```json
{
  "prompt": "Login to https://example.com and verify the dashboard",
  "user_id": "user123",
  "tenant_id": "org456",
  "test_case_id": "tc789",
  "max_steps": 20
}
```

**Response:** Server-Sent Events (SSE) stream

**Events:**
- `session_created` - Session initialized
- `initializing` - Creating sandbox
- `sandbox_ready` - Sandbox ready with sandbox_id and VNC URL
- `vnc_url` - VNC WebSocket URL
- `step_start` - Step beginning (thinking + planned tools)
- `step_complete` - Step finished (tool results)
- `completed` - Session finished
- `error` - Error occurred

**Example Event:**
```json
{
  "type": "step_complete",
  "data": {
    "step_number": 3,
    "thinking": "I need to click the Sign In button",
    "tool_calls": [
      {
        "tool_name": "e2b_browser",
        "arguments": {
          "action": "click",
          "by_text": "Sign In"
        }
      }
    ],
    "tool_results": [
      {
        "tool_name": "e2b_browser",
        "success": true,
        "output": "Clicked button. URL changed to /dashboard"
      }
    ]
  }
}
```

---

#### `POST /agent/terminate/{session_id}`
Stop a running agent session.

**Response:**
```json
{
  "status": "terminated",
  "session_id": "20250127_123456_a1b2c3d4",
  "message": "Agent session terminated successfully"
}
```

---

#### `POST /agent/cancel/{session_id}`
Cancel a running agent session and properly close all records.

**Response:**
```json
{
  "status": "cancelled",
  "session_id": "20250127_123456_a1b2c3d4",
  "message": "Agent session cancelled successfully and all records closed"
}
```

**Note:** Unlike terminate, cancel marks the session as "cancelled" (not "terminated"), sets the `completed_at` timestamp, and saves a cancellation event to the agent_steps collection for proper session closure tracking.

---

#### `POST /agent/pause/{session_id}`
Pause agent execution (preserves state).

---

#### `POST /agent/resume/{session_id}`
Resume paused agent execution.

---

#### `POST /agent/intervene/{session_id}`
Inject guidance message and auto-resume.

**Request:**
```json
{
  "message": "Stop testing and use terminate tool"
}
```

---

#### `GET /agent/sessions`
List all active agent sessions.

**Response:**
```json
{
  "active_sessions": 2,
  "sessions": [
    {
      "session_id": "20250127_123456_a1b2c3d4",
      "status": "running",
      "sandbox_id": "sandbox_abc123"
    }
  ]
}
```

---

### Test Run Endpoints

#### `POST /api/runs/execute`
Execute a test run (multiple test cases).

**Request:**
```json
{
  "run_id": "run_xyz789",
  "tenant_id": "org456",
  "parallel": false
}
```

**Response:**
```json
{
  "success": true,
  "run_id": "run_xyz789",
  "message": "Run execution started with 3 test cases",
  "test_case_count": 3
}
```

**Note:** Execution happens in background. Frontend watches Firestore for live updates.

---

#### `POST /agent/replay/{tenant_id}/{test_case_id}`
Replay proven steps from a test case (SSE stream).

**Events:**
- `replay_start` - Execution starting
- `steps_loaded` - Proven steps loaded
- `sandbox_ready` - Sandbox created with VNC URL
- `step_start` - Step starting
- `tool_result` - Tool executed
- `replay_complete` - Execution finished
- `cleanup_complete` - Sandbox cleaned up

---

### Utility Endpoints

#### `GET /health`
Health check endpoint.

**Response:**
```json
{
  "status": "healthy",
  "service": "E2B Agent API",
  "active_sessions": 2
}
```

---

## ğŸ¤– Agent System

### Agent Hierarchy

```
BaseAgent (Abstract)
    â”‚
    â”œâ”€ ToolCallAgent (ReAct Pattern)
    â”‚      â”‚
    â”‚      â””â”€ E2BTestOpsAI (Web Automation)
    â”‚             â”‚
    â”‚             â””â”€ E2BTestOpsAISubAgent (Delegation)
```

### BaseAgent

**Responsibilities:**
- State management (`IDLE`, `RUNNING`, `FINISHED`, `ERROR`)
- Message memory management
- Step execution loop
- Max steps enforcement

**Key Methods:**
- `async def run(request)` - Main execution loop
- `async def step()` - Single step execution (abstract)
- `update_memory()` - Add messages to conversation

---

### ToolCallAgent

**Responsibilities:**
- LLM communication
- Tool call handling
- ReAct pattern implementation
- Firestore integration
- Message history management

**Key Methods:**
- `async def think()` - LLM decision making
- `async def act()` - Tool execution
- `async def execute_tool()` - Single tool execution
- `async def cleanup()` - Resource cleanup

**Features:**
- Parallel tool calls (multiple tools per turn)
- Automatic message truncation (keeps last 50 messages)
- Proven steps tracking
- Execution history for AI analysis
- Sub-agent result integration

---

### E2BTestOpsAI

**Responsibilities:**
- E2B sandbox initialization
- Browser tool setup
- Vision tool setup
- Sub-agent tool setup
- Desktop/VNC setup

**Available Tools:**
- `planning` - Task breakdown and progress tracking
- `e2b_browser` - Playwright browser automation
- `e2b_vision` - Screenshot viewing (OCR)
- `e2b_sub_agent` - Delegate complex subtasks
- `ai_proven_steps` - Analyze and save proven steps
- `terminate` - Complete the session

**Configuration:**
- `max_steps`: 20 (default)
- `max_observe`: 10000 (result truncation)
- `system_prompt`: Detailed instructions for web automation
- `next_step_prompt`: Per-step guidance

---

## ğŸ”§ Tool System

### Tool Architecture

All tools inherit from `BaseTool`:

```python
class BaseTool(ABC, BaseModel):
    name: str
    description: str
    parameters: Optional[dict] = None
    
    async def execute(self, **kwargs) -> Any:
        """Tool implementation"""
```

### Core Tools

#### 1. **Planning Tool** (`planning`)

Manages high-level task plans.

**Commands:**
- `create(plan_id, title, steps)` - Create new plan
- `get(plan_id)` - View plan status
- `mark_step(plan_id, step_index, step_status, step_notes)` - Update step status

**Step States:**
- `not_started` - Not yet begun
- `in_progress` - Currently executing (ONLY ONE allowed at a time)
- `completed` - Successfully finished
- `blocked` - Cannot complete due to error

**Example:**
```python
# Create plan
await planning.execute(
    command="create",
    plan_id="login_test",
    title="Login and validate dashboard",
    steps=[
        "Navigate to login page",
        "Complete login process",
        "Validate dashboard elements"
    ]
)

# Mark step as in progress
await planning.execute(
    command="mark_step",
    plan_id="login_test",
    step_index=0,
    step_status="in_progress"
)
```

---

#### 2. **Browser Tool** (`e2b_browser`)

Playwright-based browser automation with stable locators.

**Key Actions:**

**Navigation:**
- `navigate_to(url)` - Go to URL (must include `https://`)
- `go_back()` - Browser back button
- `wait(seconds)` - Pause execution

**Interactions (Stable Locators):**
- `click(by_text='Sign In')` - Click by visible text
- `click(by_role='button', has_text='Submit')` - Click by ARIA role + text
- `fill(by_placeholder='Email', text='user@example.com')` - Fill input by placeholder
- `fill(by_label='Password', text='secret')` - Fill input by label
- `fill(by_id='username', text='user')` - Fill by ID attribute
- `send_keys(keys='Enter')` - Send keyboard keys

**Element Discovery:**
- `get_by_role(role='button')` - Find all buttons/links/inputs
- `get_headings()` - Get page headings structure
- `get_elements()` - List all interactive elements

**Assertions (for Validation):**
- `assert_element_visible(search_text='News', assertion_description='...')`
- `assert_element_hidden(search_text='Loading', assertion_description='...')`
- `assert_url_contains(expected_text='/dashboard', assertion_description='...')`
- `assert_text_contains(search_text='Welcome', expected_text='John', assertion_description='...')`
- `assert_count_equals(search_text='article', expected_count=5, locator_type='role', assertion_description='...')`
- `assert_has_value(index=0, expected_value='test@example.com', assertion_description='...')`

**Why Stable Locators?**
- âœ… Text/placeholders rarely change
- âœ… Works across page updates
- âœ… Playwright auto-waits for elements
- âŒ Indices break when DOM structure changes

**Example:**
```python
# Modern approach (stable)
await browser.execute(action="navigate_to", url="https://example.com")
await browser.execute(action="click", by_text="Sign In")
await browser.execute(action="fill", by_placeholder="Email", text="user@example.com")
await browser.execute(action="fill", by_placeholder="Password", text="secret")
await browser.execute(action="click", by_role="button", has_text="Submit")
await browser.execute(action="assert_url_contains", expected_text="/dashboard", 
                      assertion_description="Login successful")

# DEPRECATED approach (unstable - indices change!)
await browser.execute(action="get_elements")  # Returns: [0] button, [1] input...
await browser.execute(action="click_element", index=0)  # âŒ Don't use!
await browser.execute(action="input_text", index=1, text="user@example.com")  # âŒ Don't use!
```

---

#### 3. **Sub-Agent Tool** (`e2b_sub_agent`)

Delegates complex subtasks to specialized agent with isolated context.

**Parameters:**
- `task` (required) - Specific instruction (e.g., "Login with provided credentials")
- `context` (optional) - Current browser state (e.g., "Already on login page")
- `max_attempts` (optional) - Max steps for sub-agent (default: 20)

**Benefits:**
- Isolated LLM context (doesn't bloat main agent conversation)
- Can retry multiple approaches
- Returns only success/failure summary
- Main agent sees 1 step instead of 10+

**Example:**
```python
# Instead of this (bloats main agent context):
# Step 5: Click Sign In button
# Step 6: Fill email field
# Step 7: Fill password field
# Step 8: Click submit
# Step 9: Verify login
# Step 10: Check dashboard URL
# ... 6 steps in main agent!

# Do this (clean main agent context):
result = await sub_agent.execute(
    task="Login to the application with email user@example.com and password secret. Verify login was successful by checking URL change.",
    context="Currently on homepage at https://example.com",
    max_attempts=20
)
# Result: "âœ… Login successful, now on dashboard"
# Only 1 step in main agent!
```

---

#### 4. **Vision Tool** (`e2b_vision`)

View screenshots saved in the sandbox (OCR-enabled).

**Actions:**
- `see_image(file_path)` - View screenshot with OCR text extraction

**Use Cases:**
- Last resort when browser locators fail
- Verify visual elements
- Extract text from images

**Example:**
```python
# Browser already saves screenshots automatically
# Use vision to view the saved screenshot
result = await vision.execute(
    action="see_image",
    file_path="screenshot.png"
)
# Returns: Screenshot with extracted text
```

---

#### 5. **AI Proven Steps Tool** (`ai_proven_steps`)

Analyzes execution history and generates proven steps for replay.

**Parameters:**
- `summary` - Brief task summary (e.g., "Login and validate dashboard")

**Process:**
1. Extracts execution history from agent
2. Identifies ACTION tools (navigate, click, fill)
3. Extracts VALIDATIONS (assertions)
4. Combines into step format:
```python
{
  "step_number": 1,
  "action": {"tool_name": "e2b_browser", "arguments": {...}},
  "validation": {"type": "assert_element_visible", "description": "..."}
}
```
5. Saves to Firestore test_case

**Example:**
```python
# At end of session
await ai_proven_steps.execute(
    summary="Login to example.com and validate news section"
)
```

---

#### 6. **Terminate Tool** (`terminate`)

Ends the agent session.

**Parameters:**
- `status` - `success` or `failed`
- `message` - Completion message

**Example:**
```python
await terminate.execute(
    status="success",
    message="All validations passed, task complete"
)
```

---

## ğŸ“Š Data Flow

### 1. **Session Creation Flow**

```
User Request
    â”‚
    â–¼
FastAPI (api_server.py)
    â”‚
    â”œâ”€ Generate session_id
    â”œâ”€ Save to Firestore (agent_sessions)
    â”‚
    â–¼
E2BTestOpsAI.create()
    â”‚
    â”œâ”€ Create E2B sandbox (~30s)
    â”œâ”€ Start Playwright browser
    â”œâ”€ Start desktop + VNC
    â”œâ”€ Initialize tools
    â”‚
    â–¼
Update Firestore
    â”œâ”€ sandbox_id
    â”œâ”€ vnc_url
    â”œâ”€ status: "running"
    â”‚
    â–¼
Start ReAct Loop
```

---

### 2. **Step Execution Data Flow**

```
Think Phase
    â”‚
    â”œâ”€ LLM receives messages
    â”œâ”€ Returns thinking + tool_calls
    â”‚
    â–¼
Save to Firestore (IMMEDIATE)
    â”œâ”€ agent_steps/{doc_id}
    â”œâ”€ thinking: "I need to click Sign In"
    â”œâ”€ tool_calls: [{"tool_name": "e2b_browser", ...}]
    â”œâ”€ status: "executing"
    â”‚
    â–¼
Act Phase
    â”‚
    â”œâ”€ Execute tool.execute()
    â”œâ”€ Get result
    â”‚
    â–¼
Update Firestore (IMMEDIATE)
    â”œâ”€ agent_steps/{doc_id}
    â”œâ”€ tool_results: [{"success": true, ...}]
    â”œâ”€ status: "success"
    â”‚
    â–¼
Update Session Metadata
    â”œâ”€ agent_sessions/{session_id}
    â”œâ”€ last_output: "Clicked Sign In button"
    â”œâ”€ total_tokens: 12450
    â”œâ”€ total_cost: 0.18
```

---

### 3. **Proven Steps Replay Data Flow**

```
POST /agent/replay/{tenant_id}/{test_case_id}
    â”‚
    â–¼
Get test_case from Firestore
    â”œâ”€ proven_steps: [...]
    â”‚
    â–¼
Create E2B sandbox
    â”‚
    â–¼
For each proven_step:
    â”‚
    â”œâ”€ Extract: {action, validation}
    â”‚
    â”œâ”€ Execute action (tool.execute)
    â”‚   â”œâ”€ navigate_to(url)
    â”‚   â”œâ”€ click(by_text="Sign In")
    â”‚   â”œâ”€ fill(by_placeholder="Email", ...)
    â”‚   â””â”€ ...
    â”‚
    â”œâ”€ Execute validation (if present)
    â”‚   â”œâ”€ assert_element_visible(...)
    â”‚   â”œâ”€ assert_url_contains(...)
    â”‚   â””â”€ ...
    â”‚
    â”œâ”€ Save execution_step to Firestore
    â”‚   â”œâ”€ execution_id
    â”‚   â”œâ”€ step_index
    â”‚   â”œâ”€ success: true/false
    â”‚
    â”œâ”€ Update run result
    â”‚   â”œâ”€ current_step: N
    â”‚   â”œâ”€ passed_steps: X
    â”‚   â”œâ”€ failed_steps: Y
    â”‚
    â”‚ If validation fails:
    â”‚   â””â”€ Break (stop execution)
    â”‚
    â–¼
Cleanup sandbox
    â”‚
    â–¼
Update run status
    â”œâ”€ status: "passed" / "failed"
    â”œâ”€ completed_at: timestamp
```

---

## âš™ï¸ Configuration

### LLM Configuration

```toml
[llm]
model = "claude-3-5-sonnet-20241022"
base_url = "https://api.anthropic.com/v1"
api_key = "sk-ant-..."
max_tokens = 4096
temperature = 1.0
api_type = "openai"
api_version = ""

# Optional: Token limits
max_input_tokens = 1000000  # Max tokens to use across session

# Optional: Pricing (for cost tracking)
[llm.pricing]
input_price_low = 3.0   # $ per million tokens (â‰¤200K context)
input_price_high = 6.0  # $ per million tokens (>200K context)
output_price_low = 15.0
output_price_high = 22.5
tier_threshold = 200000
```

### E2B Configuration

```toml
[e2b]
e2b_api_key = "e2b_..."
template = "base"  # or custom template ID
timeout = 300
cwd = "/home/user"
```

**Custom Template:**
To use a pre-built template with Playwright pre-installed:
1. Build template: `cd e2b_template && e2b template build`
2. Note template ID: `e2b-xxxxxxxxxxxx`
3. Update config: `template = "e2b-xxxxxxxxxxxx"`

### Firestore Configuration

```toml
[firestore]
enabled = true
service_account_path = "config/firebase-service-account.json"
collection = "agent_steps"
storage_bucket = "your-project.appspot.com"
```

**Firestore Collections:**
- `agent_sessions` - Active and completed sessions
- `agent_steps` - Step-by-step execution logs
- `test_cases` - Validated test cases with proven steps
- `runs` - Test run executions
- `agent_sessions_executions` - Replay execution tracking
- `agent_sessions_executions_steps` - Replay step details

**Firebase Storage Buckets:**
- `screenshots/{user_id}/{session_id}/` - Screenshots
- `artifacts/{user_id}/{session_id}/` - Generated files (HTML, JSON, etc.)

---

## ğŸ§ª Development

### Running Locally

```bash
# Activate virtual environment
source venv/bin/activate

# Run server (development mode)
python api_server.py

# Server starts on http://localhost:8000
# API docs: http://localhost:8000/docs
```

### Testing

```bash
# Run tests
pytest

# Run specific test
pytest tests/test_agent.py::test_browser_navigation

# Run with coverage
pytest --cov=app --cov-report=html
```

### Debugging

**Enable Debug Logging:**
```python
# In app/logger.py
logger.add("debug.log", level="DEBUG")
```

**View Sandbox Logs:**
```python
# Inside E2B sandbox
result = sandbox.exec("cat /tmp/browser.log")
print(result.stdout)
```

**Connect to VNC:**
Use the VNC URL from session to view live browser:
```
wss://<sandbox-id>.e2b.dev:6080/websockify
```

### Project Structure

```
testopsai-be/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ agent/
â”‚   â”‚   â”œâ”€â”€ base.py              # BaseAgent
â”‚   â”‚   â”œâ”€â”€ toolcall.py          # ToolCallAgent (ReAct)
â”‚   â”‚   â””â”€â”€ e2b_agent.py         # E2BTestOpsAI
â”‚   â”œâ”€â”€ tool/
â”‚   â”‚   â”œâ”€â”€ base.py              # BaseTool
â”‚   â”‚   â”œâ”€â”€ planning.py          # PlanningTool
â”‚   â”‚   â”œâ”€â”€ ai_proven_steps.py   # AI Proven Steps
â”‚   â”‚   â”œâ”€â”€ terminate.py         # Terminate
â”‚   â”‚   â”œâ”€â”€ tool_collection.py   # Tool management
â”‚   â”‚   â””â”€â”€ e2b/
â”‚   â”‚       â”œâ”€â”€ e2b_browser_tool.py   # Browser automation
â”‚   â”‚       â”œâ”€â”€ e2b_vision_tool.py    # Screenshots + OCR
â”‚   â”‚       â””â”€â”€ e2b_sub_agent_tool.py # Sub-agent delegation
â”‚   â”œâ”€â”€ e2b/
â”‚   â”‚   â”œâ”€â”€ sandbox.py           # E2B sandbox wrapper
â”‚   â”‚   â””â”€â”€ tool_base.py         # E2B tool base class
â”‚   â”œâ”€â”€ prompt/
â”‚   â”‚   â”œâ”€â”€ testopsai.py         # Agent prompts
â”‚   â”‚   â””â”€â”€ toolcall.py          # ToolCall agent prompts
â”‚   â”œâ”€â”€ config.py                # Configuration management
â”‚   â”œâ”€â”€ firestore.py             # Firestore client
â”‚   â”œâ”€â”€ llm.py                   # LLM client wrapper
â”‚   â”œâ”€â”€ schema.py                # Pydantic schemas
â”‚   â”œâ”€â”€ webhook.py               # Step execution schema
â”‚   â””â”€â”€ logger.py                # Logging setup
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.toml              # Main configuration
â”‚   â””â”€â”€ firebase-service-account.json  # Firebase credentials
â”œâ”€â”€ e2b_template/
â”‚   â”œâ”€â”€ e2b.Dockerfile           # E2B template definition
â”‚   â””â”€â”€ start_desktop.sh         # Desktop startup script
â”œâ”€â”€ api_server.py                # FastAPI server
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ README.md                    # This file
```

---

## ğŸ¯ Key Design Decisions

### 1. **Stable Locators over Indices**

**Problem:** Element indices change when page structure updates.

**Solution:** Use text-based, role-based, and attribute-based locators:
- `by_text="Sign In"` - Visible text (buttons, links)
- `by_placeholder="Email"` - Input placeholder
- `by_role="button"` - ARIA role
- `by_id="username"` - HTML ID attribute

**Benefits:**
- âœ… Works across page updates
- âœ… Self-documenting (clear what's being clicked)
- âœ… Playwright auto-waits for elements

---

### 2. **Sub-Agent Delegation**

**Problem:** Complex tasks bloat main agent's LLM context.

**Solution:** Delegate to sub-agents with isolated context.

**Example:**
```
Main Agent Context:
- Step 1: Navigate to site
- Step 2: Sub-agent: Login [1 step]
- Step 3: Sub-agent: Extract data [1 step]
Total: 3 steps

Without Sub-Agents:
- Step 1-10: Navigate + try 5 different login approaches
- Step 11-20: Try 3 different extraction methods
Total: 20 steps (context bloated!)
```

---

### 3. **Immediate Firestore Saves**

**Problem:** Frontend needs real-time updates during long-running sessions.

**Solution:** Save to Firestore IMMEDIATELY after each step.

**Implementation:**
1. Think phase: Save thinking + planned tools (status: "executing")
2. Act phase: Update with tool results (status: "success")
3. Frontend listens to Firestore changes for live updates

---

### 4. **Proven Steps with Validations**

**Problem:** AI-generated tests need validations to catch regressions.

**Solution:** Extract both ACTIONS and ASSERTIONS from execution history.

**Structure:**
```python
{
  "action": {"tool_name": "e2b_browser", "arguments": {...}},
  "validation": {"type": "assert_element_visible", "description": "..."}
}
```

**Replay Logic:**
1. Execute action
2. If action succeeds, run validation
3. If validation fails, mark test as failed
4. Continue to next step only if both pass

---

### 5. **E2B Sandboxes for Isolation**

**Problem:** Running browsers on server is resource-intensive and insecure.

**Solution:** Each session runs in isolated E2B sandbox.

**Benefits:**
- âœ… Full isolation (no cross-session contamination)
- âœ… Automatic cleanup (no resource leaks)
- âœ… Scalable (E2B handles infrastructure)
- âœ… Full internet access (no firewall restrictions)
- âœ… VNC for live viewing

---

## ğŸ“ Best Practices

### For Users

1. **Write Clear Prompts:**
   - âœ… "Login to https://example.com with user@test.com, then validate the news section is visible"
   - âŒ "Test the login feature"

2. **Include URLs with Protocol:**
   - âœ… `https://example.com`
   - âŒ `example.com` (will fail)

3. **Use Specific Validation Instructions:**
   - âœ… "Validate that the News section is visible on the page"
   - âŒ "Check the page" (too vague)

4. **Watch VNC During Execution:**
   - Use VNC URL to see what's happening in real-time
   - Intervene if agent is stuck (`/agent/intervene`)

---

### For Developers

1. **Always Use Stable Locators:**
```python
# âœ… Good
await browser.execute(action="click", by_text="Sign In")
await browser.execute(action="fill", by_placeholder="Email", text="...")

# âŒ Bad
await browser.execute(action="click_element", index=0)
```

2. **Add Assertions to Proven Steps:**
```python
# After action, add validation
await browser.execute(action="click", by_text="Sign In")
await browser.execute(action="assert_url_contains", 
                      expected_text="/dashboard",
                      assertion_description="Login successful")
```

3. **Use Sub-Agents for Complex Tasks:**
```python
# If task involves 5+ browser actions, delegate to sub-agent
result = await sub_agent.execute(
    task="Complete the multi-step checkout process",
    context="Items already in cart"
)
```

4. **Handle Errors Gracefully:**
```python
try:
    result = await tool.execute(**args)
    if hasattr(result, 'error') and result.error:
        # Handle tool error
        await planning.execute(command="mark_step", 
                               step_status="blocked",
                               step_notes=str(result.error))
except Exception as e:
    # Handle exception
    logger.error(f"Tool execution failed: {e}")
```

---

## ğŸ”® Future Enhancements

- **Parallel Test Execution** - Run multiple test cases simultaneously
- **Screenshot Comparison** - Visual regression testing
- **Test Scheduling** - Cron-based test runs
- **Email Notifications** - Alert on test failures
- **Custom Assertions** - User-defined validation logic
- **Test Retry Logic** - Auto-retry flaky tests
- **Performance Metrics** - Track test execution times
- **Test Dependencies** - Run tests in specific order

---

## ğŸ“š Documentation

### User Guides
- **[Quick Start](QUICK_START.md)** - Get running in 5 minutes
- **[Environment Variables](ENVIRONMENT.md)** - All configuration options
- **[API Reference](#api-reference)** - Complete API documentation (this file)

### Deployment
- **[Deployment Guide](DEPLOYMENT.md)** - Cloud Run, Docker, VPS, systemd
- **[E2B Template Setup](E2B_TEMPLATE_SETUP.md)** - Build custom template for faster startup
- **[Architecture](#architecture)** - System architecture and design (this file)

### Contributing
- **[Contributing Guidelines](CONTRIBUTING.md)** - How to contribute code
- **[Open Source Checklist](OPEN_SOURCE_CHECKLIST.md)** - Pre-commit verification
- **[Project Structure](#project-structure)** - Codebase organization (this file)

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details.

Copyright (c) 2025 T4U Automation

---

## ğŸ¤ Contributing

We welcome contributions! See **[CONTRIBUTING.md](CONTRIBUTING.md)** for:
- Development workflow
- Coding standards
- Pull request process
- Testing guidelines

**Key principles:**
- âœ… Use stable locators (by_role, by_text, by_placeholder)
- âŒ Never use indices for click/fill actions
- âœ… Include assertions for validation
- âœ… Follow existing code style

---

## ğŸ“ Support

- **Documentation:** See [Quick Links](#quick-links) above
- **Issues:** [GitHub Issues](https://github.com/t4u-automation/t4u-backend/issues)
- **Discussions:** [GitHub Discussions](https://github.com/t4u-automation/t4u-backend/discussions)

### Common Issues

See **[DEPLOYMENT.md](DEPLOYMENT.md#common-issues)** for troubleshooting:
- E2B sandbox timeout
- Firebase permission denied
- LLM API errors
- Locator timeouts

---

## ğŸŒŸ Show Your Support

If you find T4U useful, please:
- â­ Star the repository
- ğŸ› Report bugs via [GitHub Issues](https://github.com/t4u-automation/t4u-backend/issues)
- ğŸ’¡ Suggest features via [Discussions](https://github.com/t4u-automation/t4u-backend/discussions)
- ğŸ¤ Contribute via [Pull Requests](CONTRIBUTING.md)

---

**Built with â¤ï¸ for the test automation community**

[![GitHub](https://img.shields.io/github/stars/t4u-automation/t4u-backend?style=social)](https://github.com/t4u-automation/t4u-backend)

